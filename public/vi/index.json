[
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Văn A\nSố điện thoại: 0989888999\nEmail: Anguyenvan@gmail.com\nTrường: Đại học Sư phạm Kỹ thuật TP.HCM\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTruyền tải video hiệu quả và AI thị giác tại biên với Realtek, Plumerai và Amazon Kinesis Video Streams Trí tuệ nhân tạo (AI) tại biên đang trở nên phổ biến trong các thiết bị video thông minh. Ví dụ, các camera Nhà thông minh và chuông cửa video đã cách mạng hóa việc giám sát tại nhà. Từ những công cụ ghi hình đơn giản và xem từ xa, các thiết bị này đã tiến hóa thành những người quan sát thông minh. Với sự tích hợp AI, các camera ngày nay có thể chủ động phân tích cảnh, cảnh báo người dùng về các sự kiện chuyển động, nhận diện khuôn mặt quen thuộc, phát hiện việc giao hàng gói hàng và điều chỉnh hành vi ghi hình một cách linh hoạt. Các camera giám sát doanh nghiệp là một ví dụ khác. Những camera này có độ phân giải vượt trội, khả năng tính toán nâng cao và có thể hỗ trợ các mô hình AI phức tạp hơn. Những khả năng nâng cao này mang lại khả năng phát hiện sắc nét hơn ở khoảng cách xa hơn.\nNhư đã minh họa, khách hàng đòi hỏi các hệ thống giám sát thông minh có thể xử lý dữ liệu cục bộ trong khi vẫn duy trì quyền riêng tư và giảm chi phí băng thông. Để đáp ứng những nhu cầu này, nhóm AWS Internet of Things (AWS IoT) đã phát triển một giải pháp camera thông minh cùng với các đối tác AWS, kết hợp Amazon Kinesis Video Streams, vi điều khiển Ameba Pro2 tiết kiệm năng lượng của Realtek và các mô hình học máy hiệu quả từ Plumerai. Bài viết này cung cấp hướng dẫn cho việc tải video kích hoạt theo sự kiện kết hợp với xử lý thuật toán phát hiện con người tại biên.\nKiến trúc giải pháp Hình dưới đây minh họa kiến trúc giải pháp mà bài viết này sử dụng:\nBắt đầu từ camera, firmware của thiết bị đã tích hợp Realtek SDK để truy cập các mô-đun camera thông qua các API được xác định. Các đoạn video được truyền đến các mô hình học máy của Plumerai để thực hiện phát hiện đối tượng. Ứng dụng mẫu thêm kết quả phát hiện dưới dạng lớp phủ bounding box trên các đoạn video gốc. Ứng dụng này liên tục tải các đoạn video lên đám mây thông qua Kinesis Video Streams Producer SDK.\n(Bạn cũng có thể thiết lập để chỉ tải lên các đoạn video 20 giây khi có phát hiện.) Producer SDK sử dụng PutMedia API với kết nối HTTPS lâu dài để tải liên tục các mảnh MKV. Dữ liệu media được thu nhận và lưu trữ bền vững để phân tích về sau. Một ứng dụng front-end có thể phát lại video trực tiếp hoặc video đã ghi thông qua HLS hoặc DASH. Giải pháp cung cấp dữ liệu video và âm thanh vào Large Language Models (LLMs) để khai thác insight từ Agentic AI.\n(Tìm kiếm video ngữ nghĩa sẽ được trình bày trong bài tiếp theo.) Điểm nổi bật của tích hợp Amazon Kinesis Video Streams Kinesis Video Streams mang lại nhiều lợi ích cho camera IP, robot và ô tô:\nKiến trúc được quản lý hoàn toàn → đội kỹ thuật chỉ cần tập trung vào phát triển tính năng. AWS SDK mã nguồn mở, tránh phụ thuộc nền tảng. Mô hình trả phí theo sử dụng linh hoạt, không tốn chi phí cho đến khi camera hoạt động thật. Plumerai Plumerai chuyên về AI nhúng và tối ưu mô hình để chạy trên phần cứng nhỏ, hiệu năng thấp:\nTối ưu hoá CPU Arm Cortex-M ở mức assembly, tận dụng lệnh DSP. Neural Architecture Search (NAS) chọn kiến trúc AI tối ưu cho Realtek NPU. Tận dụng hardware accelerators (scaler, format converter) của Realtek. Tích hợp tốt với RTOS và khung truyền thông Realtek. Khởi động nhanh, mô hình huấn luyện trên 30 triệu video \u0026amp; ảnh. Hiệu suất thực tế:\nĐộ chính xác cao, bộ nhớ thấp. Góc nhìn rộng 180°. Phát hiện người trong phạm vi 20m+. Theo dõi 20 người cùng lúc. Hoạt động tốt cả ban ngày và đêm tối. Realtek Ameba Pro2 Realtek Ameba Pro2 bao gồm:\nIntegrated Video Encoder (IVE) Image Signal Processor (ISP) Video Offload Engine (VOE) Neural Processing Unit (NPU) Parallel Processing Unit (PPU) Khả năng chính:\nTốn rất ít CPU. Phản hồi gần thời gian thực. Xử lý video ngay cả khi đang khởi động. Truyền tới SD Card và Cloud qua WiFi/Ethernet. Hỗ trợ mạnh mẽ inference AI tại biên. Hướng dẫn từng bước Điều kiện tiên quyết Bạn cần:\nTài khoản AWS có quyền: Đăng nhập AWS Console API Kinesis Video Streams\n(GetDataEndpoint, DescribeStream, PutMedia) Tạo EC2 instance để build SDK Stream có tên kvs-plumerai-realtek-stream Realtek Ameba Pro2 MCU Kinh nghiệm Linux basic SDK Realtek \u0026amp; thư viện Plumerai Kết nối internet Thiết lập môi trường xây dựng Tạo EC2 Instance Vào AWS Console → EC2. Launch instance: Tên: KVS_AmebaPlumerAI_poc OS: Ubuntu 22.04 LTS Loại máy: t3.large Key pair: kvs-plumerai-realtek-keypair Storage: 100 GiB Mở port SSH. SSH vào EC2: ssh -o ServerAliveInterval=60 -i kvs-plumerai-realtek-keypair.pem ubuntu@54.xxx.yyy.zzz "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: AWS IAM, triển khai EC2, mạng VPC, và các khái niệm cơ bản về Site-to-Site VPN\nTuần 3: High Availability, Scalability, RDS, Aurora, ElastiCache, Route 53, và Solutions Architecture\nTuần 4: Lưu trữ Amazon S3, CloudFront, Global Accelerator, Storage Gateway, FSx, và các dịch vụ tích hợp (SQS, SNS, Step Functions)\nTuần 5: Containers trên AWS (ECS, EKS), Kiến trúc Serverless (Lambda, API Gateway), và các dịch vụ Database (RDS, DynamoDB, Redshift, ElastiCache)\nTuần 6: Data \u0026amp; Analytics (Athena, Glue, Kinesis), Machine Learning (SageMaker, Rekognition), Monitoring (CloudWatch, CloudTrail), và IAM nâng cao\nTuần 7: Bảo mật \u0026amp; Mã hóa AWS (KMS, CloudHSM, Shield, WAF), Mạng VPC, và các chiến lược Disaster Recovery \u0026amp; Backup\nTuần 8: Kiến trúc Giải pháp Nâng cao, IoT Core, Ground Station, RoboMaker, và AWS Whitepapers\nTuần 9: Báo cáo tổng kết AWS Cloud Journey, thiết kế kiến trúc hệ thống AWS đầy đủ, và ôn tập Tuần 1-8\nTuần 10: Hoàn thành Project Proposal và thiết kế AWS Architecture Diagram\nTuần 11: Nhật ký Tuần 11\nTuần 12: Nhật ký Tuần 12\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Chuyển đổi số cho Mini-market trên nền tảng đám mây AWS Giải pháp E-commerce .NET 3-tier áp dụng Repository và Unit of Work Pattern 1. Tóm tắt điều hành Bản đề xuất này trình bày một giải pháp end-to-end nhằm \u0026ldquo;Chuyển đổi số cho Mini-market trên nền tảng đám mây AWS\u0026rdquo;. Các mini-market truyền thống hiện đang đối mặt với ba thách thức lớn: (1) Quản lý kho thủ công (bằng Excel/sổ tay) gây thất thoát doanh thu và lãng phí nguồn lực; (2) Lệ thuộc 100% vào kênh bán offline, bỏ lỡ thị trường e-commerce đang phát triển và mất khả năng cạnh tranh; và (3) Quy trình vận hành chậm chạp (như tra giá thủ công), mang lại trải nghiệm khách hàng kém.\nGiải pháp của nhóm là xây dựng một nền tảng e-commerce và quản lý vận hành toàn diện. Về software architecture, nhóm sẽ sử dụng kiến trúc .NET 3-lớp (ASP.NET Core MVC, EF Core) kết hợp Repository Pattern và Unit of Work Pattern. Về infrastructure architecture được thiết kế theo AWS Well-Architected Framework, chạy trên AWS Elastic Beanstalk (cho backend .NET), Amazon RDS for SQL Server (cho database), và Amazon S3 (cho static assets). Hệ thống được tối ưu hiệu năng bằng CloudFront và ElastiCache, và bảo mật bằng WAF, VPC, và NAT Gateway. Quy trình triển khai được tự động hóa hoàn toàn bằng CI/CD pipeline tích hợp với GitHub.\nBusiness benefits là ngay lập tức, bao gồm tự động hóa quản lý kho (giảm thất thoát) và mở ra một kênh doanh thu online mới. Về investment, chi phí hạ tầng trong 12 tháng đầu tiên là gần như bằng 0 nhờ tận dụng AWS Free Tier (ví dụ: RDS Express Edition, EC2 t3.micro). Chi phí vận hành dài hạn (sau Free Tier) cũng rất thực tế, ước tính chỉ khoảng 138.06 USD/tháng cho toàn bộ hệ thống. Với investment ban đầu tối thiểu và khả năng giải quyết trực tiếp các vấn đề gây thất thoát doanh thu, ROI là rất cao và gần như tức thì.\nDự án được đề xuất triển khai trong 11 tuần, chia thành 4 phases (giai đoạn) chính: (1) Foundation \u0026amp; Architecture, (2) Core Feature Development, (3) AWS Integration \u0026amp; CI/CD, và (4) Finalization \u0026amp; Deployment. Kết quả mong đợi được đo lường bằng các success metrics cụ thể: giảm 90% sai sót kho vận, giảm 50% thời gian thanh toán, và đạt 20% doanh thu từ kênh online trong 6 tháng đầu. Giải pháp này không chỉ giải quyết các vấn đề trước mắt mà còn cung cấp cho mini-market một nền tảng scalable để đưa ra quyết định dựa trên dữ liệu trong tương lai.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác doanh nghiệp bán lẻ nhỏ và vừa, đặc biệt là mô hình \u0026ldquo;mini-market\u0026rdquo; truyền thống tại Việt Nam, đang vận hành dựa trên các quy trình thủ công đã lỗi thời. Trong bối cảnh thị trường ngày càng số hóa, việc không áp dụng công nghệ vào môi trường làm việc đã tạo ra một số vấn đề, trực tiếp ảnh hưởng đến khả năng tồn tại và phát triển của họ.\nMột số vấn đề chính\nVấn đề về quản lý kho thủ công dẫn đến tính thiếu chính xác trong số liệu và lãng phí nguồn lực: Đa số mini-market hiện nay quản lý hàng nghìn mã sản phẩm (SKUs) bằng sổ sách hoặc file Excel. Việc nhập/xuất kho và kiểm kê cuối ngày hoàn toàn dựa vào việc đếm và nhập thủ công. Việc này có thể dẫn đến sai sót trong dữ liệu vì quy trình nhập tay rất dễ xảy ra nhầm lẫn, tiêu biểu như mã sản phẩm và số lượng, việc này gây ra chênh lệch lớn giữa dữ liệu \u0026ldquo;trên sổ\u0026rdquo; và \u0026ldquo;thực tế\u0026rdquo; trong kho. Việc kiểm hàng hóa thủ công như này cũng sẽ đòi hỏi nguồn lực cao khi mà nhân viên sẽ phải dành hàng giờ mỗi ngày để kiểm kê, đối chiếu và chỉnh sữa báo cáo, thay vì tập trung vào phần bán hàng hoặc chăm sóc khách hàng. Cuối cùng là thất thoát tài chính, khi mà dữ liệu không được nhập chính xác, chủ cửa hàng sẽ không thể kiểm soát được tình trạng của hàng hóa như là hàng hóa hết hạn, hàng hóa bị hư hỏng, hoặc là bị mất cắp, dẫn đến thất thoát 5-10% giá trị hàng tồn kho hàng tháng. Vấn đề lệ thuộc vào bán hàng offline, bỏ lỡ thị trường E-commerce: Thông thường các mini-market ở Việt Nam đa số sẽ phụ thuộc vào khách vãng lai(offline). Họ cũng bị giới hạn bởi vị trí địa lí (chỉ phục vụ trong khu vực) và tệp khách hàng quen thuộc. Các cửa hàng như này sẽ đứng ngoài thị trường E-commerce, bỏ lỡ tệp khách hàng trẻ vốn đã quen thuộc với việc mua sắm online. Họ sẽ không thể cạnh tranh về sự tiện lợi như là đặt hàng 24/7 hay là giao hàng tận nơi so với các chuỗi cửa hàng tiện lợi lớn như là Circle K hoặc 7-Eleven và các ứng dụng giao hàng như Grab và Shopee, dẫn đến mất nguy cơ mất khách hàng theo thời gian. Vấn đề về vận hành và trải nghiệm của khách hàng: Quy trình thanh toán và tra cứu thông tin ở các mini-market truyền thống thông thường sẽ rất chậm chạp. Khi khách hàng hỏi về giá, thông tin của sản phẩm, hoặc là chương trình khuyến mãi, nhân viên (đặc biệt là nhân viên mới) sẽ phải tra cứu thủ công trong sổ sách dẫn đến tốn thời gian. Việc bắt khách hàng phải chờ đợi lâu để tra cứu thông tin hoặc tính tiền sẽ tạo ra sự ức chế và thiếu chuyên nghiệp. Nhân viên sẽ mất quá nhiều thời gian cho các tác vụ đơn giản, dễ nhầm lẫn (như là đọc nhầm giá do chữ viết xấu), làm giảm số lượng khách hàng có thể phục vụ trong giờ cao điểm. 3. Kiến trúc giải pháp Kiến trúc được thiết kế để giải quyết các vấn đề đã nêu, bằng cách kết hợp kiến trúc phần mềm .NET 3-lớp (Tier-3) với các dịch vụ đám mây được quản lý (Managed Services) của AWS. Kiến trúc này tuân thủ các nguyên tắc của AWS Well-Architected Framework, đảm bảo tính bảo mật, hiệu năng cao, khả năng phục hồi lỗi và tối ưu chi phí.\nDịch vụ AWS sử dụng\nAWS Elastic Beanstalk: Dịch vụ PaaS (Platform as a Service) được chọn để triển khai ứng dụng .NET 3-lớp (gồm Lớp Presentation WebShop và Lớp Application Services). Beanstalk tự động hóa 100% việc quản lý hạ tầng, bao gồm tự động tạo Auto Scaling Group (ASG) để đảm bảo tính co giãn (Scalability) và tiết kiệm chi phí.\nAmazon RDS (SQL Server): Dịch vụ Cơ Sở Dữ Liệu (CSDL) (Managed Relational Database Service) để host Lớp Persistence. SQL Server được chọn vì ứng dụng .NET của nhóm đã được phát triển và tối ưu cho SQL Server. Việc sử dụng RDS for SQL Server cho phép di chuyển (migrate) ứng dụng lên AWS mà không cần thay đổi code ở Lớp Dữ liệu. RDS cũng sẽ tự động hóa các tác vụ phức tạp như sao lưu (backup) hàng ngày, vá lỗi (patching) và phục hồi khi có sự cố (failover). Về tính bảo mật thì RDS được đặt trong Private Subnet, không thể truy cập trực tiếp từ Internet, chỉ cho phép ứng dụng trên Beanstalk kết nối. Và về vấn đề tối ưu chi phí, để tối ưu chi phí trong giai đoạn đầu, chúng ta có thể bắt đầu với phiên bản SQL Server Express Edition trên RDS, phiên bản này nằm trong Free Tier của AWS.\nAmazon S3: Dịch vụ lưu trữ đối tượng (Object Storage). Dùng để lưu trữ các static assets như hình ảnh sản phẩm, file CSS, và JavaScript. S3 cung cấp chi phí cực rẻ và khả năng mở rộng vô hạn.\nAmazon CloudFront: Dịch vụ Content Delivery Network - CDN. CloudFront lưu đệm (cache) các file tĩnh từ S3 tại các máy chủ (Edge Locations) trên toàn cầu, giúp người dùng tải trang nhanh hơn đáng kể. Giúp giảm tải trực tiếp cho máy chủ Beanstalk, và giúp ứng dụng .NET tập trung xử lý logic.\nAmazon WAF và Route 53: WAF (Web Application Firewall) và Route 53 (Dịch vụ DNS). WAF được liên kết với CloudFront để chặn các cuộc tấn công web phổ biến (như SQL injection, XSS). Route 53 cung cấp tên miền cho người dùng.\nAmazon ElastiCache (Redis): Dịch vụ in-memory data stores. Giúp giảm tải tối đa cho CSDL RDS khi có các truy vấn lặp đi lặp lại (ví dụ: lấy danh sách sản phẩm trang chủ). Ứng dụng .NET sẽ cache các dữ liệu \u0026ldquo;nóng\u0026rdquo; này trên ElastiCache, giúp tăng tốc độ phản hồi. Tương tự như RDS, ElastiCache cũng được đặt trong Private Subnet để đảm bảo an toàn.\nNAT Gateway: Dịch vụ Network Address Translation. NAT sẽ cung cấp lối ra Internet an toàn cho các dịch vụ trong Private Subnet (như Elastic Beanstalk). Điều này cho phép máy chủ tải về các bản vá bảo mật mà không bị truy cập trực tiếp từ bên ngoài.\nAWS CodePipeline/CodeBuild: Dịch vụ tích hợp và triển khai liên tục (CI/CD). Các dịch vụ này được tích hợp với GitLab để tự động hóa quy trình: (1) CodeBuild build code .NET, (2) CodePipeline deploy phiên bản mới lên Elastic Beanstalk.\nLuồng dữ liệu\n[1]-[2] Người dùng truy cập tên miền (qua Route 53) và được điều hướng đến CloudFront. Amazon WAF sẽ lọc request này.\n[3] (Luồng Tĩnh) Nếu là file tĩnh (ảnh, css), CloudFront lấy trực tiếp từ Amazon S3.\n[4]-[6] (Luồng Động) Nếu là request động, CloudFront chuyển tiếp qua Internet Gateway đến Application Load Balancer, sau đó ALB gửi request vào Elastic Beanstalk.\n[7]-[8] Ứng dụng .NET (trên Beanstalk) sẽ kiểm tra ElastiCache trước, nếu không có sẽ truy vấn Amazon RDS.\n[9]-[10] Khi Elastic Beanstalk cần ra Internet (để tải bản vá), nó sẽ đi qua NAT Gateway rồi ra Internet Gateway.\n[11]-[14] (Luồng CI/CD) Khi Dev push code lên Github, CodePipeline và CodeBuild sẽ tự động build và triển khai (deploy) phiên bản mới lên Elastic Beanstalk.\n4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án sẽ được chia thành 4 giai đoạn chính, kéo dài trong 11 tuần để đảm bảo tiến độ và chất lượng:\nXây dựng nền móng kỹ thuật: Tập trung xây dựng nền móng kỹ thuật, bao gồm việc chốt mô hình dữ liệu cho các thực thể chính, thiết lập cấu trúc solution .NET 3-lớp (Domain, Application, Persistence, WebShop), khởi tạo repository trên Github, và tìm hiểu về các dịch vụ của AWS. (Tuần 1-4)\nXây dựng các tính năng cốt lõi: Hoàn thiện Lớp Persistence (Repositories, Unit of Work) và Lớp Application (Services) cho các nhiệm vụ chính như quản lý sản phẩm, người dùng và đơn hàng. Song song đó, Lớp WebShop (Controllers, Views) sẽ được xây dựng cho các luồng đăng nhập, giỏ hàng, thanh toán và bắt đầu viết Unit Test cho Services. (Tuần 5-7)\nTích hợp các dịch vụ của AWS: Tích hợp Amazon S3 cho ảnh sản phẩm, ElastiCache (Redis) để cache. Nhóm cũng sẽ hoàn thiện CI/CD Pipeline để tự động deploy lên môi trường Staging trên Elastic Beanstalk và thực hiện Integration Testing. (Tuần 8-10)\nHoàn thiện và triển khai: Cấu hình các dịch vụ bảo mật như CloudFront, WAF, và Route 53. Sau đó, triển khai phiên bản 1.0 lên Elastic Beanstalk, thực hiện UAT cuối cùng, và thiết lập giám sát cơ bản qua CloudWatch. (Tuần 11)\nYêu cầu kỹ thuật\nBackend: ASP.NET Core MVC 9.0. ORM: Entity Framework Core. Database: MS SQL Server 2022 (Local) và Amazon RDS for SQL Server (Cloud). Frontend: Bootstrap 5, jQuery, và Bootstrap Icons. Cloud Platform (AWS): Elastic Beanstalk, RDS, S3, CloudFront, WAF, Route 53, ElastiCache, VPC, NAT Gateway, CodePipeline, CodeBuild. Source Control: Git. Tools: Visual Studio 2022, Docker Desktop. Phương pháp phát triển\nÁp dụng phương pháp Agile (Scrum-like) để linh hoạt điều chỉnh theo yêu cầu và đảm bảo tiến độ, bám sát 4 giai đoạn triển khai đã đề ra. Mọi công việc (features, bugs) sẽ được theo dõi và quản lý thông qua Kanban board, giúp nhóm dễ dàng nắm bắt tiến độ của từng tác vụ (ví dụ: To Do, In Progress, Done). Mọi code mới phải được review thông qua merge requests trên Github trước khi được merge vào nhánh main, đảm bảo chất lượng code nhất quán.\nChiến lược kiểm thử\nĐể đảm bảo chất lượng và tính ổn định, nhóm sẽ thực hiện 3 cấp độ kiểm thử. Đầu tiên là Unit Testing, tập trung 100% vào Lớp Application (ví dụ: ProductService, OrderService) bằng cách giả lập các repository để cách ly Business Logic, sử dụng các framework kiểm thử tiêu chuẩn của .NET. Cấp độ thứ hai là Integration Testing, thực hiện trên môi trường Staging (trên Elastic Beanstalk) để kiểm tra sự tương tác giữa Lớp Application và Lớp Persistence (EF Core) với CSDL Amazon RDS thật. Cuối cùng, User Acceptance Testing sẽ được thực hiện trên môi trường Production để nhóm kiểm tra các luồng chức năng hoàn chỉnh trên giao diện người dùng như \u0026ldquo;Đăng ký, Đăng nhập, Thanh toán\u0026rdquo;.\nKế hoạch triển khai\nÁp dụng quy trình CI/CD tự động hóa hoàn toàn. Quy trình được kích hoạt tự động mỗi khi Dev push code lên Github. Github sẽ gửi webhook kích hoạt AWS CodePipeline, dịch vụ này sẽ lấy code và ra lệnh cho AWS CodeBuild thực hiện biên dịch dự án .NET, chạy Unit Test, và đóng gói ứng dụng thành file .zip. Nếu CodeBuild thành công, CodePipeline sẽ lấy file .zip và tự động triển khai phiên bản mới này lên môi trường Staging trên Elastic Beanstalk.\n5. Lộ trình \u0026amp; Mốc triển khai Dự án được lên kế hoạch thực hiện trong 11 tuần, chia thành 4 giai đoạn chính. Tiến độ này đảm bảo thời gian cho việc phát triển, integration, và testing kỹ lưỡng.\nPhase 1 (Tuần 1 - 4): Giai đoạn này tập trung xây dựng nền tảng kỹ thuật, bao gồm việc chốt data models, thiết lập Solution Architecture .NET 3-lớp, khởi tạo Github Repository, và tìm hiểu về các dịch vụ AWS. Milestone của giai đoạn này là Solution Architecture và Repository được thiết lập, cùng với môi trường AWS (VPC, Subnets).\nPhase 2 (Tuần 5 - 7): Sau khi Phase 1 hoàn thành, nhóm sẽ xây dựng các core features, hoàn thiện Lớp Persistence và Application (Quản lý Sản phẩm, Đơn hàng) và các feature flows cơ bản trên WebShop (Auth, Giỏ hàng). Milestone là các feature flows chính (Đăng nhập, Xem sản phẩm, Giỏ hàng, Thanh toán) hoạt động ổn định trên local, và Unit Test cho Services.\nPhase 3 (Tuần 8 - 10): Phụ thuộc vào Phase 2, giai đoạn này sẽ integrate các dịch vụ AWS như Amazon S3 cho ảnh sản phẩm và ElastiCache (Redis) để cache. Milestone là CI/CD pipeline hoạt động, tự động deploy lên Staging environment trên Elastic Beanstalk thành công và Integration Testing hoàn tất.\nPhase 4 (Tuần 11): Giai đoạn cuối cùng này tập trung vào hoàn thiện và triển khai, phụ thuộc vào bản build Staging ổn định từ Phase 3. Nhóm sẽ cấu hình các dịch vụ bảo mật (CloudFront, WAF, Route 53). Milestone là Version 1.0 được triển khai thành công lên Production environment (Elastic Beanstalk), User Acceptance Testing cuối cùng hoàn tất, và hệ thống được monitoring qua CloudWatch.\n6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nChi phí hạ tầng\nBản ước tính từ AWS Pricing Calculator cho thấy chi phí vận hành hàng tháng của architecture này là 138.06 USD, với chi phí trả trước là 0.00 USD. Chiến lược tối ưu chi phí của nhóm tập trung vào việc tận dụng tối đa AWS Free Tier và các managed services. Con số 138.06 USD/tháng là một chi phí thực tế cho việc vận hành dài hạn (sau 12 tháng) một hệ thống e-commerce hoàn chỉnh, có khả năng scale và bảo mật cao.\nChi phí cho Elastic Beanstalk được chia nhỏ thành các resources mà nó quản lý: Amazon EC2 (1 instance t3a.small) với chi phí 19.15 USD/tháng và Elastic Load Balancing (1 Application Load Balancer) với chi phí 18.69 USD/tháng. Dịch vụ Amazon VPC có chi phí 46.02 USD/tháng, đây là chi phí cho 1 NAT Gateway, một thành phần bắt buộc cho thiết kế bảo mật Private Subnet của Elastic Beanstalk. Về database và cache, Amazon RDS for SQL Server (phiên bản Express Edition trên db.t3.micro) có chi phí 25.86 USD/tháng, và Amazon ElastiCache (cache.t4g.micro) là 17.52 USD/tháng. Các dịch vụ bảo mật và CI/CD như WAF (7.20 USD/tháng), CloudFront (2.43 USD/tháng), Route 53 (0.90 USD/tháng), S3 (0.17 USD/tháng), và CodeBuild (0.12 USD/tháng) chiếm phần chi phí còn lại.\nChiến lược tối ưu chi phí quan trọng nhất là tận dụng AWS Free Tier trong 12 tháng đầu. Mặc dù tổng ước tính là 138.06 USD/tháng, nhiều services cốt lõi trong đây (bao gồm EC2 t3a.small, RDS db.t3.micro, ElastiCache t4g.micro, S3, và CloudFront) đều nằm trong Free tier miễn phí 12 tháng. Do đó, chi phí vận hành thực tế trong năm đầu tiên sẽ thấp hơn đáng kể, chủ yếu chỉ bao gồm chi phí cho NAT Gateway (46.02 USD) và WAF (7.20 USD).\nVề phần tính toán ROI, và đầu tư lúc ban đầu gần như bằng 0 (do chi phí hạ tầng được nằm trong Free Tier và development costs là công sức của nhóm trong kỳ thực tập). Phần lợi nhuận gần như là ngay lập tức, vì giải pháp giải quyết trực tiếp các vấn đề thất thoát doanh thu (từ quản lý kho thủ công) và bỏ lỡ thị trường (do chỉ bán offline) đã nêu trong Problem Statement (Phần 1). Do đó, ROI (lợi tức đầu tư) là rất cao.\n7. Đánh giá rủi ro Một số rủi ro tiềm ẩn nằm trong ba lĩnh vực: Technical, Business, và Operational. Vậy nên một kế hoạch giảm thiểu và kế hoạch dự phòng đã được chuẩn bị cho các rủi ro có tác động cao.\nTechnical: Quá tải Hệ thống (Performance Bottleneck):\nImpact: High | Probability: Medium Đây là rủi ro hệ thống bị chậm hoặc sập khi có lượng traffic cao. Chiến lược giảm thiểu của nhóm là sử dụng ElastiCache để giảm tải query cho RDS, cấu hình Auto Scaling (trong Elastic Beanstalk) với các trigger hợp lý (ví dụ: CPU \u0026gt; 70%), và dùng CloudFront để cache file tĩnh. Kế hoạch dự phòng là sử dụng CloudWatch Alarms để cảnh báo ngay lập tức, và nếu RDS quá tải, nhóm sẽ thực hiện vertical scaling instance của RDS ngay lập tức. Business: Người dùng không chấp nhận (Low User Adoption):\nImpact: High | Probability: Medium Đây là rủi ro các chủ mini-market thấy giải pháp quá phức tạp và không sử dụng. Để giảm thiểu rủi ro này, nhóm sẽ bám sát thiết kế frontend (Bootstrap) đơn giản, thu thập feedback của chủ tiệm sớm từ Phase 2, và cung cấp tài liệu hướng dẫn. Kế hoạch dự phòng là nếu adoption thấp sau khi deploy, nhóm sẽ thực hiện một Sprint bổ sung (Phase 5) để ưu tiên điều chỉnh các features dựa trên feedback thu được. Operational: Mất hoặc rò rỉ dữ liệu (Data Loss / Breach):\nImpact: Critical | Probability: Low Chiến lược giảm thiểu của nhóm là cấu hình RDS tự động backup hàng ngày, đặt RDS và Beanstalk trong Private Subnet, sử dụng WAF để chặn tấn công, và quản lý connection string qua environment variables của Beanstalk. Kế hoạch dự phòng là nếu mất dữ liệu, nhóm sẽ thực hiện Point-in-Time Recovery (PITR) ngay lập tức từ backup của RDS. 8. Kết quả kỳ vọng Mục tiêu của giải pháp này là giải quyết trực tiếp các vấn đề đã nêu trong phần Tuyên bố vấn đề. Về business metrics, nhóm kỳ vọng giảm 90% sai sót trong quản lý kho (so với Excel/sổ tay), giảm 50% thời gian thanh toán tại quầy, và đạt được ít nhất 20% doanh thu mới từ kênh online trong 6 tháng đầu. Về technical metrics, mục tiêu là duy trì uptime (thời gian hoạt động) 99.9%, đảm bảo page load time (thời gian tải trang) trung bình dưới 2 giây (nhờ CloudFront và ElastiCache), và deployment frequency (tần suất triển khai) ổn định qua CI/CD pipeline.\nCác benefits được kỳ vọng là sẽ gia tăng theo thời gian. Trong short-term (0-6 tháng), chủ mini-market sẽ thấy trải nghiệm người dùng được cải thiện ngay lập tức và phần vận hành được cải thiện đáng kể (quản lý kho tự động). Trong medium-term (6-18 tháng), giá trị đến từ việc mở rộng thị trường (tiếp cận khách hàng online) và bắt đầu thu thập được business data có giá trị. Long-term value và strategic capabilities thu được chính là khả năng đưa ra quyết định dựa trên dữ liệu (data-driven decisions) (ví dụ: biết sản phẩm nào bán chạy) và khả năng scale hệ thống dễ dàng (thêm nhiều cửa hàng mới) nhờ Solution Architecture trên Elastic Beanstalk và RDS.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.2-week2/",
	"title": "Nhật ký Tuần 2",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 2 Tìm hiểu và áp dụng AWS IAM để quản lý danh tính và quyền truy cập. Thực hành triển khai và quản lý EC2 Instance. Khám phá Amazon VPC và AWS Site-to-Site VPN để hiểu các khái niệm mạng cơ bản. Củng cố kiến thức nền tảng về ngôn ngữ lập trình C#. Tổng quan Nhiệm vụ Tuần Ngày Hoạt động Ngày bắt đầu Ngày kết thúc Tài liệu tham khảo 1 - Tìm hiểu các khái niệm cơ bản về IAM + Học cách tạo và gán user, group, role + Thiết lập permission policy cho từng nhóm quyền + Kiểm tra truy cập qua IAM Console 15/09/2025 15/09/2025 https://000002.awsstudygroup.com/ 2 - Thực hành triển khai EC2 Instance và cấu hình cơ bản + Chọn Amazon Linux 2023 (Free Tier) + Cấu hình key pair, security group (SSH access) + Kết nối qua SSH và kiểm tra hoạt động + Làm quen với VPC networking (subnet, route table, Internet Gateway) 16/09/2025 16/09/2025 https://000003.awsstudygroup.com/ 3 - Khám phá Amazon Bedrock Playground + Trải nghiệm các mô hình như Claude 3 Haiku và Titan Text + Tạo prompt mẫu và đánh giá phản hồi + Thử nghiệm nhiều tình huống khác nhau để hiểu cách AI xử lý 17/09/2025 17/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Ôn tập lập trình C# cơ bản + Ôn lại cấu trúc điều khiển, vòng lặp, lớp và đối tượng + Thực hành viết code nhỏ minh họa thao tác logic + Tổng hợp thuật ngữ và dịch vụ AWS qua ChatGPT để ghi nhớ 18/09/2025 18/09/2025 - Thành tựu Tuần 2 Hiểu và áp dụng được các nguyên tắc của IAM, bao gồm tạo người dùng, vai trò và chính sách truy cập.\nBiết cách cấp quyền hạn chế và tạo nhóm quyền phù hợp với từng nhu cầu. Nắm được mối quan hệ giữa user, group, role và policy trong AWS. Thực hành thành công việc triển khai, kết nối và quản lý EC2 Instance trong gói Free Tier.\nNắm được cách khởi tạo, dừng, xóa instance và quản lý qua EC2 Console. Biết cách truy cập SSH và kiểm tra hoạt động của máy ảo. Nắm vững kiến thức nền tảng về Amazon VPC, bao gồm:\nSubnet, Route Table, Internet Gateway, NAT Gateway và cấu trúc mạng logic. Hiểu cơ chế định tuyến và cách cô lập mạng ảo an toàn. Tìm hiểu cơ chế của AWS Site-to-Site VPN, giúp kết nối an toàn giữa mạng nội bộ (on-premises) và VPC.\nBiết cách hoạt động của tunnel VPN và cách thiết lập kết nối giữa hai hệ thống. Trải nghiệm Amazon Bedrock Playground, làm quen với các mô hình AI như Claude và Titan.\nHiểu cách viết prompt hiệu quả để nhận phản hồi chính xác. Thử nghiệm nhiều chủ đề khác nhau để hiểu cơ chế sinh nội dung (generative AI). Củng cố kiến thức lập trình C#, song song với thực hành các dịch vụ AWS.\nViết các chương trình nhỏ phục vụ kiểm tra logic và học cú pháp cơ bản. Có cái nhìn tổng quan về các nhóm dịch vụ chính trong AWS:\nCompute (EC2, Lambda), Networking (VPC, VPN), và AI/ML (Bedrock). Hiểu được cách các dịch vụ này phối hợp để tạo nên một hệ thống cloud hoàn chỉnh. "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.3-week3/",
	"title": "Nhật ký Tuần 3",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 3 Hiểu các khái niệm cốt lõi về High Availability (Tính sẵn sàng cao) và Scalability (Khả năng mở rộng) trong môi trường đám mây. Tìm hiểu các dịch vụ cơ sở dữ liệu được quản lý của AWS như RDS, Aurora, và ElastiCache. Học cách cấu hình và quản lý Amazon Route 53 cho DNS và điều hướng truy cập. Nghiên cứu các mô hình kiến trúc giải pháp điển hình trên AWS và thực hành thiết kế hệ thống tối ưu. Tổng quan Nhiệm vụ Tuần Ngày Hoạt động Ngày bắt đầu Ngày kết thúc Tài liệu tham khảo 1 - Nghiên cứu về High Availability \u0026amp; Scalability + Tìm hiểu mô hình triển khai Multi-AZ + Cấu hình thử nghiệm Auto Scaling Group + Hiểu vai trò của Elastic Load Balancer (ELB) trong việc phân phối lưu lượng 22/09/2025 22/09/2025 https://aws.amazon.com/autoscaling/ 2 - Tìm hiểu Amazon RDS và Aurora + Tạo instance RDS ở chế độ Multi-AZ + Thử nghiệm read replica và failover + Học về cơ chế Aurora cluster và khả năng tự phục hồi 23/09/2025 23/09/2025 https://aws.amazon.com/rds/ 3 - Làm việc với Amazon ElastiCache + So sánh hai engine Redis và Memcached + Thực hành tạo cache cluster + Giám sát hiệu suất qua CloudWatch 24/09/2025 24/09/2025 https://aws.amazon.com/elasticache/ 4 - Thực hành cấu hình Amazon Route 53 + Tạo hosted zone và bản ghi DNS + Thiết lập failover routing + Kiểm tra latency-based routing giữa các vùng 25/09/2025 25/09/2025 https://aws.amazon.com/route53/ 5–6 - Tìm hiểu về Classic Solutions Architecture + Phân tích mô hình multi-tier và serverless + Nghiên cứu các pattern thiết kế có tính mở rộng cao và sẵn sàng trong sản xuất + Thiết kế mô hình nhỏ kết hợp EC2, RDS, và ELB 26/09/2025 27/09/2025 https://aws.amazon.com/architecture/ Thành tựu Tuần 3 Nắm vững các chiến lược về High Availability:\nHiểu cách triển khai Multi-AZ và cơ chế failover tự động. Cấu hình Auto Scaling Group để tự động mở rộng hoặc thu hẹp tài nguyên. Sử dụng Elastic Load Balancer (ELB) để đảm bảo phân phối lưu lượng và duy trì thời gian hoạt động liên tục. Mở rộng kiến thức về các dịch vụ cơ sở dữ liệu của AWS:\nQuản lý RDS và hiểu lợi ích hiệu năng của Aurora. Biết cách sử dụng ElastiCache để tăng tốc độ phản hồi ứng dụng bằng bộ nhớ đệm. Làm chủ các khái niệm về DNS và định tuyến thông qua Amazon Route 53:\nTạo và cấu hình hosted zone, routing policy, và health check. Thực hành failover routing và latency-based routing giữa các khu vực. Tăng cường tư duy thiết kế kiến trúc hệ thống qua Classic AWS Solutions:\nBiết cách kết hợp các dịch vụ Compute, Database, và Networking để xây dựng hệ thống linh hoạt. Thiết kế mô hình thử nghiệm nhỏ tập trung vào tính ổn định, khả năng mở rộng, và tối ưu chi phí. Tổng hợp kiến thức đa lĩnh vực về Compute, Database, Networking, và Architecture Design, sẵn sàng cho các module chuyên sâu tiếp theo của AWS.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.4-week4/",
	"title": "Nhật ký Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 4 Hiểu và tối ưu hóa lưu trữ dữ liệu trên Amazon S3. Nâng cao kỹ năng quản lý, bảo mật, và tối ưu hiệu suất S3. Tìm hiểu về CloudFront, Global Accelerator, và các phương pháp giảm độ trễ khi phân phối nội dung. Nghiên cứu các dịch vụ lưu trữ khác của AWS như FSx, Storage Gateway, và tích hợp hệ thống qua SQS, SNS, Step Functions. Tổng quan Nhiệm vụ Tuần Ngày Hoạt động Ngày bắt đầu Ngày kết thúc Tài liệu tham khảo 1 - Tìm hiểu Amazon S3 cơ bản + Tạo bucket và upload dữ liệu mẫu + So sánh các loại storage tiers (Standard, Infrequent Access, Glacier) + Phân tích chi phí lưu trữ theo từng lớp dữ liệu 29/09/2025 29/09/2025 https://aws.amazon.com/s3/ 2 - Nâng cao quản lý Amazon S3 + Cấu hình Cross-Region Replication (CRR) giữa hai vùng khác nhau + Thiết lập Lifecycle Policy để tự động chuyển dữ liệu sang Glacier + Bật Versioning và kiểm tra khả năng phục hồi dữ liệu 30/09/2025 30/09/2025 https://docs.aws.amazon.com/AmazonS3/ 3 - Thực hành bảo mật dữ liệu S3 + Áp dụng IAM policy và bucket policy hạn chế truy cập + Cấu hình Server-Side Encryption (SSE) và AWS KMS + Kiểm tra thiết lập ngăn chặn truy cập công khai (Block Public Access) 01/10/2025 01/10/2025 https://docs.aws.amazon.com/s3/security/ 4 - Khám phá CloudFront \u0026amp; Global Accelerator + Cấu hình CloudFront Distribution để phân phối nội dung từ S3 + Kết hợp Global Accelerator để giảm độ trễ truy cập toàn cầu + Đánh giá hiệu suất qua công cụ đo tốc độ truy cập 02/10/2025 02/10/2025 https://aws.amazon.com/cloudfront/ 5 - Tìm hiểu AWS Storage Extras + Làm quen với AWS Storage Gateway và cơ chế hybrid storage + Cấu hình thử nghiệm FSx for Windows và FSx for Lustre + So sánh hiệu năng giữa các giải pháp lưu trữ 03/10/2025 03/10/2025 https://aws.amazon.com/storage/ 6 - Nghiên cứu AWS Integration \u0026amp; Messaging + Học cách sử dụng SQS cho message queue + Gửi và nhận thông báo qua SNS + Thiết lập AWS Step Functions để điều phối workflow giữa các dịch vụ 04/10/2025 04/10/2025 https://aws.amazon.com/messaging/ Thành tựu Tuần 4 Hiểu rõ cách hoạt động của Amazon S3 và phân loại các lớp lưu trữ dữ liệu:\nBiết cách lựa chọn storage class phù hợp với từng nhu cầu sử dụng. Nắm rõ chi phí, hiệu suất và độ bền (durability) của từng lớp dữ liệu. Thực hành nâng cao trong quản lý S3:\nThiết lập thành công Cross-Region Replication giữa hai vùng AWS. Áp dụng Lifecycle Policy để tối ưu chi phí lưu trữ dài hạn. Bật Versioning và khôi phục dữ liệu bị xóa hoặc ghi đè. Củng cố kỹ năng bảo mật dữ liệu S3:\nÁp dụng chính sách IAM, Bucket Policy, và mã hóa SSE, KMS. Đảm bảo bucket không công khai, tuân thủ nguyên tắc bảo mật AWS. Làm quen với CloudFront và Global Accelerator:\nThiết lập phân phối nội dung toàn cầu và kiểm tra độ trễ. Hiểu cách CDN và accelerator cải thiện trải nghiệm người dùng. Khám phá các dịch vụ lưu trữ mở rộng của AWS:\nLàm quen với Storage Gateway cho môi trường hybrid. Tìm hiểu FSx for Windows File Server và FSx for Lustre cho workload hiệu năng cao. Hiểu cơ chế Integration \u0026amp; Messaging trên AWS:\nSử dụng SQS để tách hàng đợi xử lý. Gửi thông báo qua SNS và điều phối workflow với Step Functions. Tổng hợp kiến thức toàn diện về Storage, Security, Networking, và Integration, chuẩn bị cho giai đoạn học về Serverless \u0026amp; Application Deployment trong những tuần tiếp theo.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.5-week5/",
	"title": "Nhật ký Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 5 Học cách triển khai và quản lý container trên AWS bằng ECS, EKS, và Docker. Hiểu các khái niệm và lợi ích của kiến trúc Serverless. Thiết kế và xây dựng ứng dụng Serverless tích hợp Lambda, API Gateway, S3, và DynamoDB. Tìm hiểu các dịch vụ cơ sở dữ liệu AWS như RDS, Aurora, DynamoDB, Redshift, và ElastiCache. Tổng quan Nhiệm vụ Tuần Ngày Hoạt động Ngày bắt đầu Ngày kết thúc Tài liệu tham khảo 1 - Tìm hiểu về Containers on AWS + Phân biệt giữa ECS và EKS + Triển khai container mẫu bằng ECS (Fargate) + Làm quen với khái niệm container orchestration 06/10/2025 06/10/2025 https://aws.amazon.com/containers/ 2 - Thực hành với EKS (Elastic Kubernetes Service) + Tạo cụm EKS và triển khai ứng dụng mẫu + Kết nối Docker image từ local lên ECR (Elastic Container Registry) + Theo dõi cụm EKS qua AWS Console 07/10/2025 07/10/2025 https://aws.amazon.com/eks/ 3 - Khám phá Serverless Overview + Hiểu khái niệm event-driven computing + Tạo và kiểm thử AWS Lambda cơ bản + Tích hợp Lambda với API Gateway để tạo endpoint 08/10/2025 08/10/2025 https://aws.amazon.com/lambda/ 4 - Thiết kế Serverless Architecture + Kết nối Lambda với DynamoDB và S3 + Xây dựng pipeline dữ liệu đơn giản bằng Step Functions + Kiểm thử quy trình serverless end-to-end 09/10/2025 09/10/2025 https://aws.amazon.com/architecture/serverless/ 5 - Tìm hiểu về Databases in AWS + So sánh giữa cơ sở dữ liệu quan hệ và NoSQL + Tạo cơ sở dữ liệu thử nghiệm trong RDS và DynamoDB + Làm quen với Redshift cho phân tích dữ liệu và ElastiCache để tăng tốc truy xuất 10/10/2025 10/10/2025 https://aws.amazon.com/databases/ 6 - Ôn tập toàn bộ kiến thức trong tuần + Triển khai dự án nhỏ kết hợp Lambda, API Gateway, DynamoDB, và S3 + Ghi chú lại bài học và các kinh nghiệm tối ưu 11/10/2025 11/10/2025 - Thành tựu Tuần 5 Hiểu rõ và thực hành với Containers trên AWS:\nTriển khai container bằng ECS (Fargate) và EKS. Nắm vững cách quản lý image với ECR và nguyên tắc container orchestration. Nắm bắt kiến thức nền tảng về kiến trúc Serverless:\nXây dựng và chạy các hàm AWS Lambda theo hướng sự kiện (event-driven). Tích hợp Lambda với API Gateway để tạo các endpoint RESTful. Thiết kế và triển khai thành công ứng dụng Serverless hoàn chỉnh:\nKết nối Lambda với DynamoDB và S3 để xử lý dữ liệu tự động. Sử dụng Step Functions để điều phối quy trình làm việc. Củng cố kiến thức về các dịch vụ cơ sở dữ liệu của AWS:\nLàm việc với RDS cho hệ quản trị quan hệ và DynamoDB cho NoSQL. Tìm hiểu Aurora về khả năng mở rộng và Redshift cho phân tích dữ liệu. Sử dụng ElastiCache để tăng hiệu năng truy xuất dữ liệu. Áp dụng tư duy DevOps trong quá trình triển khai:\nKết hợp giữa Containers, Serverless, và Databases trong cùng môi trường triển khai. Hiểu được quy trình phát triển liền mạch giữa các dịch vụ AWS. Hoàn thiện kiến thức về Compute, Database, và Serverless, sẵn sàng cho Tuần 6 với chủ đề Monitoring, CI/CD và Infrastructure as Code (IaC).\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong thời gian thực tập tại [Tên Công Ty/Tổ Chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi có cơ hội tham gia vào dự án thực tế “Chuyển đổi số cho Mini-market trên nền tảng AWS Cloud”. Trong quá trình thực tập, tôi đã áp dụng các kiến thức được học ở trường—từ công nghệ phần mềm, cơ sở dữ liệu, đến điện toán đám mây—để xây dựng một nền tảng e-commerce .NET 3 tầng kết hợp với các dịch vụ AWS.\nTôi tham gia vào nhiều đầu việc quan trọng của dự án, bao gồm:\nThiết kế và triển khai Domain Layer, Application Layer, Persistence Layer, WebShop Layer theo mô hình Repository \u0026amp; Unit of Work\nXây dựng các tính năng cốt lõi như quản lý sản phẩm, giỏ hàng, thanh toán, xác thực người dùng\nTích hợp các dịch vụ AWS như: S3, RDS, CloudFront, Elastic Beanstalk, ElastiCache, VPC, WAF, NAT Gateway, CI/CD với CodePipeline\nHỗ trợ xây dựng tài liệu kiến trúc hệ thống, biểu đồ kiến trúc, và tính toán chi phí AWS\nThực hiện testing, phân tích lỗi và triển khai staging/production\nNgoài kỹ năng kỹ thuật, tôi còn cải thiện được kỹ năng giao tiếp, làm việc nhóm, quản lý nhiệm vụ và tư duy giải quyết vấn đề trong môi trường làm việc chuyên nghiệp.\nDưới đây là phần tự đánh giá chi tiết:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Áp dụng .NET, SQL Server, AWS Services, Git, CI/CD vào hệ thống cloud thực tế ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu nhanh các công nghệ mới như Elastic Beanstalk, CloudFront, WAF, VPC ☐ ✅ ☐ 3 Chủ động Tự nghiên cứu AWS, tự giải quyết lỗi khi develop hệ thống ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành nhiệm vụ đúng tiến độ, đảm bảo chất lượng code ✅ ☐ ☐ 5 Kỷ luật Tuân thủ quy trình Git, tài liệu, họp nhóm, và quy định môi trường làm việc ☐ ☐ ✅ 6 Tính cầu tiến Luôn tiếp nhận góp ý và cải thiện phong cách lập trình, tối ưu kiến trúc ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng rõ ràng khi thảo luận, biết trao đổi khi gặp vấn đề ☐ ✅ ☐ 8 Hợp tác nhóm Phối hợp hiệu quả với các thành viên trong xây dựng kiến trúc và phát triển tính năng ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, nghiêm túc trong công việc, thái độ tích cực ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Xử lý lỗi CI/CD, lỗi cache, sự cố networking trong VPC, deployment fail ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Xây dựng nhiều module quan trọng trong hệ thống Mini-market ✅ ☐ ☐ 12 Tổng thể Tóm tắt toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Cải thiện tính kỷ luật trong việc ghi chép tài liệu, báo cáo tiến độ và quản lý thời gian\nNâng cao khả năng phân tích – debug trong môi trường cloud phân tán\nTăng cường kỹ năng giao tiếp trong các cuộc họp kỹ thuật và trình bày giải pháp\nTiếp tục học sâu về AWS nâng cao, bảo mật hệ thống và tối ưu hiệu năng\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.6-week6/",
	"title": "Nhật ký Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 6 Tìm hiểu và thực hành các dịch vụ Data \u0026amp; Analytics của AWS. Làm quen với các dịch vụ Machine Learning (ML) như SageMaker và Rekognition. Nâng cao kỹ năng giám sát, kiểm tra, và tối ưu hiệu suất hệ thống bằng CloudWatch, CloudTrail, và Trusted Advisor. Tìm hiểu về quản lý danh tính nâng cao trong AWS bao gồm IAM Roles, Federated Access, và SSO. Tổng quan Nhiệm vụ Tuần Ngày Hoạt động Ngày bắt đầu Ngày kết thúc Tài liệu tham khảo 1 - Nghiên cứu Data \u0026amp; Analytics Services + Làm quen với Amazon Athena để truy vấn dữ liệu trực tiếp từ S3 + Tìm hiểu AWS Glue cho ETL (Extract – Transform – Load) + Giới thiệu về Amazon EMR và xử lý dữ liệu lớn (Big Data) 13/10/2025 13/10/2025 https://aws.amazon.com/athena/ 2 - Thực hành với AWS Glue \u0026amp; Kinesis + Tạo Glue crawler để tự động thu thập metadata + Thiết lập Kinesis Data Stream để xử lý dữ liệu theo thời gian thực + Kết hợp Glue và Athena để phân tích dữ liệu động 14/10/2025 14/10/2025 https://aws.amazon.com/glue/ 3 - Bắt đầu học về Machine Learning trên AWS + Làm quen với Amazon SageMaker + Tạo và huấn luyện mô hình đơn giản trên dataset mẫu + Khám phá dịch vụ Amazon Rekognition để nhận diện hình ảnh 15/10/2025 15/10/2025 https://aws.amazon.com/sagemaker/ 4 - Tiếp tục phần Machine Learning + Triển khai mô hình SageMaker lên endpoint inference + Kiểm thử và đánh giá độ chính xác mô hình + Tìm hiểu các dịch vụ ML khác như Comprehend, Translate, và Textract 16/10/2025 16/10/2025 https://aws.amazon.com/machine-learning/ 5 - Thực hành Monitoring, Audit \u0026amp; Performance + Cấu hình Amazon CloudWatch để thu thập metrics + Kích hoạt AWS CloudTrail để theo dõi hoạt động API + Sử dụng Trusted Advisor để phát hiện rủi ro và tối ưu chi phí 17/10/2025 17/10/2025 https://aws.amazon.com/cloudwatch/ 6 - Học về Advanced Identity in AWS + Tạo và quản lý IAM Roles nâng cao + Tìm hiểu Federated Access để đăng nhập qua tài khoản ngoài + Cấu hình AWS SSO (Single Sign-On) và thử nghiệm truy cập đa tài khoản 18/10/2025 18/10/2025 https://aws.amazon.com/iam/ Thành tựu Tuần 6 Nắm vững kiến thức về AWS Data \u0026amp; Analytics:\nHiểu quy trình phân tích dữ liệu sử dụng Athena, Glue, EMR, và Kinesis. Thực hành truy vấn dữ liệu S3 bằng Athena và xây dựng ETL pipeline cơ bản bằng Glue. Tạo pipeline xử lý dữ liệu thời gian thực với Kinesis Data Stream. Tiếp cận và thực hành Machine Learning trên AWS:\nHuấn luyện và triển khai mô hình mẫu bằng SageMaker. Sử dụng Rekognition để nhận diện khuôn mặt và đối tượng trong hình ảnh. Làm quen với các dịch vụ ML khác: Comprehend, Translate, Textract. Thành thạo kỹ năng giám sát và kiểm tra hệ thống:\nTheo dõi metric và log bằng CloudWatch. Ghi nhận và kiểm tra hoạt động API qua CloudTrail. Phân tích báo cáo và khuyến nghị từ Trusted Advisor để tối ưu hiệu suất. Tăng cường hiểu biết về bảo mật và quản lý danh tính nâng cao:\nTạo IAM Roles và áp dụng nguyên tắc least privilege. Tìm hiểu Federated Access cho phép đăng nhập bằng tài khoản tổ chức. Cấu hình AWS SSO để truy cập nhiều tài khoản AWS một cách an toàn và thuận tiện. Hoàn thiện kỹ năng tổng hợp giữa Data, Machine Learning, Monitoring, và Security, chuẩn bị cho tuần tiếp theo về Automation \u0026amp; Infrastructure as Code (IaC).\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc trong chương trình rất thoải mái, thân thiện và dễ trao đổi. Mọi người hỗ trợ nhau khá tích cực, đặc biệt khi mình gặp khó khăn về kỹ thuật như cấu hình AWS, triển khai Elastic Beanstalk hay xử lý lỗi CI/CD. Không gian làm việc online linh hoạt phù hợp với lịch học và làm việc cá nhân. Mình nghĩ chương trình có thể bổ sung thêm các buổi trao đổi hoặc chia sẻ định kỳ để tăng sự kết nối giữa các bạn thực tập sinh.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, nhất là trong các phần phức tạp như thiết kế kiến trúc AWS, sử dụng VPC, triển khai CI/CD và tối ưu backend .NET. Mentor không đưa đáp án ngay mà giúp mình tự phân tích và giải quyết vấn đề — đây là điều mình đánh giá rất cao. Team admin hỗ trợ tài liệu, quy trình và giải đáp thắc mắc nhanh chóng.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCác nhiệm vụ như xây dựng mô hình 3-tier .NET, Entity Framework Core, repository pattern, thiết kế database SQL Server, triển khai hệ thống lên AWS,… đều phù hợp với kiến thức mình được học. Thực tập giúp mình kết nối lý thuyết trên lớp với thực tiễn triển khai trên môi trường cloud.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTham gia dự án giúp mình học được rất nhiều mảng mới:\nKiến trúc AWS thực tế (VPC, RDS, S3, CloudFront, WAF, NAT Gateway, Elastic Beanstalk…)\nCI/CD pipeline với CodePipeline – CodeBuild\nThiết kế kiến trúc theo Well-Architected Framework\nKỹ năng viết tài liệu kỹ thuật và phân tích hệ thống Ngoài ra, kỹ năng mềm như teamwork, báo cáo tiến độ, giao tiếp khi gặp vấn đề cũng được cải thiện nhiều.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nMọi người làm việc tích cực, hỗ trợ đúng lúc và luôn tôn trọng nhau. Dù mỗi người có lịch cá nhân khác nhau, tinh thần teamwork vẫn được duy trì tốt, nhất là khi các phần kiến trúc AWS cần phải thống nhất chung. Không có áp lực không cần thiết, giúp mình phát triển thoải mái hơn.\n6. Chính sách / phúc lợi cho thực tập sinh\nChương trình tạo điều kiện giờ giấc linh hoạt và hỗ trợ tài liệu học tập đầy đủ. Ngoài ra, việc được tham gia vào dự án end-to-end thật sự là “phúc lợi lớn nhất” vì mình học được nhiều hơn môi trường học thuật thông thường.\nMột số câu hỏi khác Điều mình hài lòng nhất: Cơ hội được làm một dự án cloud thực tế từ kiến trúc → triển khai → testing → tối ưu chi phí. Đây là trải nghiệm mà trước đây mình chưa có cơ hội tiếp cận sâu như vậy.\nĐiều mình nghĩ có thể cải thiện: Có thể bổ sung thêm buổi hướng dẫn tập trung về AWS nâng cao hoặc workshop thực chiến để thống nhất kiến thức nhanh hơn.\nCó giới thiệu cho bạn bè không? Có. Vì chương trình giúp thực tập sinh được làm dự án thật, được mentor hỗ trợ tận tâm và học được kỹ năng thực tế rất giá trị.\nĐề xuất \u0026amp; mong muốn Tổ chức thêm các buổi workshop AWS (VPC nâng cao, bảo mật, tối ưu chi phí…).\nThêm buổi demo sản phẩm hoặc review sprint định kỳ để mọi người học hỏi lẫn nhau.\nNếu có thể, nên cung cấp thêm tài liệu hoặc checklist chuẩn cho quy trình triển khai AWS.\nNếu chương trình có mở rộng dự án hoặc internship nâng cao, mình rất muốn tiếp tục tham gia để phát triển thêm.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.7-week7/",
	"title": "Nhật ký Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 7 Hiểu và áp dụng các phương pháp bảo mật dữ liệu và hệ thống trong AWS. Quản lý, cấu hình và tối ưu Amazon VPC (Virtual Private Cloud) cho hệ thống mạng riêng. Học cách sao lưu, phục hồi và triển khai kế hoạch khôi phục thảm họa (Disaster Recovery) với các công cụ AWS. Tổng quan Nhiệm vụ Tuần Ngày Hoạt động Ngày bắt đầu Ngày kết thúc Tài liệu tham khảo 1 - Tìm hiểu về AWS Security \u0026amp; Encryption + Làm quen với AWS KMS (Key Management Service) để mã hóa dữ liệu + Khám phá CloudHSM cho bảo mật khóa phần cứng (Hardware Security Module) + Tìm hiểu AWS Shield và WAF để bảo vệ ứng dụng web khỏi tấn công DDoS 20/10/2025 20/10/2025 https://aws.amazon.com/security/ 2 - Thực hành KMS và Shield/WAF + Tạo và quản lý Customer Managed Keys (CMK) trong KMS + Thiết lập AWS WAF rules để chặn truy cập độc hại + Kiểm thử bảo mật ứng dụng bằng Shield Standard 21/10/2025 21/10/2025 https://docs.aws.amazon.com/kms/ 3 - Nghiên cứu Amazon VPC cơ bản + Tạo VPC, Subnet, Route Table, và Internet Gateway + Thiết lập Security Group và Network ACL để kiểm soát truy cập + Kết nối VPC với các dịch vụ khác như EC2 và RDS 22/10/2025 22/10/2025 https://aws.amazon.com/vpc/ 4 - Tìm hiểu nâng cao về VPC Networking + Thiết lập VPN Connection giữa on-premise và VPC + Giới thiệu AWS Direct Connect để kết nối vật lý + Mô phỏng mô hình phân vùng mạng an toàn (Private/Public Subnets) 23/10/2025 23/10/2025 https://docs.aws.amazon.com/vpc/ 5 - Tìm hiểu về Disaster Recovery \u0026amp; Backup + Sử dụng AWS Backup để sao lưu tài nguyên tự động + Cấu hình RDS Read Replicas để tăng khả năng chịu lỗi + Thực hành Cross-Region Failover cho kế hoạch DR 24/10/2025 24/10/2025 https://aws.amazon.com/backup/ 6 - Ôn tập và tổng hợp kiến thức tuần 7 + Kiểm thử lại các thiết lập VPC, Backup, và WAF + Viết tài liệu đánh giá bảo mật hệ thống + Tổng hợp bài học về bảo mật, mạng, và phục hồi thảm họa 25/10/2025 25/10/2025 - Thành tựu Tuần 7 Nắm vững bảo mật dữ liệu và mã hóa trong AWS:\nThực hành tạo và quản lý KMS keys để bảo vệ dữ liệu. Hiểu cơ chế hoạt động của CloudHSM trong quản lý khóa phần cứng. Cấu hình AWS Shield và WAF để bảo vệ ứng dụng khỏi tấn công DDoS và truy cập độc hại. Làm chủ mạng riêng ảo Amazon VPC:\nTạo và cấu hình VPC, subnets, route tables, Internet Gateway, và NAT Gateway. Áp dụng Security Groups và Network ACLs để kiểm soát truy cập hiệu quả. Thiết lập VPN Connection và hiểu khái niệm Direct Connect cho kết nối bảo mật cao. Hiểu rõ quy trình Disaster Recovery (DR) và sao lưu dữ liệu:\nSử dụng AWS Backup để quản lý sao lưu định kỳ. Cấu hình RDS Read Replicas để đảm bảo tính sẵn sàng dữ liệu. Thực hiện Cross-Region Failover để đảm bảo khôi phục nhanh sau thảm họa. Tăng cường khả năng thiết kế hệ thống an toàn, đáng tin cậy và có khả năng phục hồi cao.\nBiết cách kết hợp giữa Security, Networking, và Resilience trong kiến trúc AWS. Chuẩn bị kiến thức cho tuần tiếp theo về Automation, Infrastructure as Code (IaC), và DevOps Practices. "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.8-week8/",
	"title": "Nhật ký Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 8 Nâng cao kiến thức về kiến trúc hệ thống (Solutions Architecture) trong môi trường AWS. Tìm hiểu và trải nghiệm các dịch vụ mở rộng khác của AWS như IoT, Ground Station và RoboMaker. Nghiên cứu chuyên sâu các tài liệu whitepaper, kiến trúc tham chiếu và best practices chính thức từ AWS. Tổng quan Nhiệm vụ Tuần Ngày Hoạt động Ngày bắt đầu Ngày kết thúc Tài liệu tham khảo 1 - Tìm hiểu Advanced Solutions Architecture + Ôn lại các khái niệm về kiến trúc cloud cơ bản + Học về Hybrid Architecture (kết hợp on-premise và cloud) + Tìm hiểu mô hình Multi-Cloud Architecture và các tình huống sử dụng 27/10/2025 27/10/2025 https://aws.amazon.com/architecture/ 2 - Thực hành thiết kế kiến trúc + Vẽ sơ đồ hệ thống hybrid với VPC Peering, Direct Connect, và VPN + Tìm hiểu các Design Patterns phổ biến trong AWS (Microservices, Event-driven, Serverless) + Thực hành mô phỏng bằng AWS Architecture Diagram Tool 28/10/2025 28/10/2025 https://aws.amazon.com/architecture/icons/ 3 - Khám phá Other AWS Services + Làm quen với AWS IoT Core để kết nối thiết bị thông minh + Tìm hiểu AWS Ground Station cho xử lý dữ liệu vệ tinh + Giới thiệu AWS RoboMaker cho mô phỏng và triển khai robot 29/10/2025 29/10/2025 https://aws.amazon.com/iot-core/ 4 - Thực hành AWS IoT Core + Tạo và đăng ký thiết bị (Thing) + Gửi dữ liệu cảm biến mô phỏng lên cloud + Cấu hình rule để chuyển dữ liệu đến DynamoDB hoặc S3 30/10/2025 30/10/2025 https://docs.aws.amazon.com/iot/ 5 - Nghiên cứu AWS Whitepapers \u0026amp; Reference Architectures + Đọc Well-Architected Framework Whitepaper + Tìm hiểu các tài liệu về High Availability, Fault Tolerance, Security Best Practices + Ghi chú các nguyên tắc thiết kế quan trọng 31/10/2025 31/10/2025 https://aws.amazon.com/whitepapers/ 6 - Tổng kết Tuần 8 + Tóm tắt kiến thức đã học về kiến trúc, IoT và tài liệu whitepaper + So sánh kiến trúc hybrid, multicloud và serverless + Chuẩn bị nội dung cho báo cáo tổng kết khóa học AWS Cloud Journey 01/11/2025 01/11/2025 - Thành tựu Tuần 8 Nâng cao hiểu biết về Advanced Solutions Architecture:\nThiết kế kiến trúc hybrid kết hợp on-premise và AWS Cloud. Hiểu rõ mô hình Multi-Cloud và khi nào nên sử dụng. Áp dụng Design Patterns như Microservices, Event-driven và Serverless trong thiết kế hệ thống. Làm quen với các dịch vụ mở rộng của AWS:\nKết nối thiết bị thông minh bằng AWS IoT Core. Hiểu quy trình thu nhận và xử lý dữ liệu vệ tinh với AWS Ground Station. Tìm hiểu về mô phỏng robot tự động bằng AWS RoboMaker. Đọc và nghiên cứu AWS Whitepapers:\nNắm vững AWS Well-Architected Framework và 5 trụ cột chính: Operational Excellence, Security, Reliability, Performance Efficiency, Cost Optimization. Hiểu rõ các chiến lược thiết kế High Availability và Disaster Recovery. Ghi chú các Best Practices về bảo mật, tối ưu chi phí và mở rộng hệ thống. Tổng hợp kiến thức tuần 8:\nKết hợp giữa lý thuyết kiến trúc và thực hành qua các dịch vụ thực tế. Chuẩn bị cho báo cáo tổng kết và trình bày kiến trúc hệ thống hoàn chỉnh vào tuần tiếp theo. "
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.9-week9/",
	"title": "Nhật ký Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 9 Hoàn thành báo cáo tổng kết toàn bộ hành trình AWS Cloud Journey. Xây dựng và trình bày kiến trúc hệ thống hoàn chỉnh dựa trên các dịch vụ AWS đã học. Ôn tập và củng cố toàn bộ kiến thức từ Week 1 → Week 8. Chuẩn bị báo cáo, tài liệu và nội dung thuyết trình cuối kỳ. Tổng quan Nhiệm vụ Tuần Ngày Hoạt động Ngày bắt đầu Ngày kết thúc Tài liệu tham khảo 1 - Tổng hợp kiến thức từ Week 1–8 + Xem lại toàn bộ các dịch vụ AWS đã học + Đánh giá mức độ hiểu biết về Compute, Storage, Networking, Security 03/11/2025 03/11/2025 - 2 - Hoàn thiện bản kiến trúc hệ thống (Architecture Diagram) + Vẽ sơ đồ VPC tổng thể + Thể hiện Compute, RDS, S3, Load Balancer, Auto Scaling, IAM, Monitoring 04/11/2025 04/11/2025 https://aws.amazon.com/architecture/icons/ 3 - Viết báo cáo tổng kết theo 5 trụ cột Well-Architected + Security + Reliability + Performance + Cost Optimization + Operational Excellence 05/11/2025 05/11/2025 https://aws.amazon.com/architecture/well-architected/ 4 - Ôn tập các chủ đề quan trọng + VPC nâng cao, VPN, Direct Connect + Load Balancing, Auto Scaling + S3 Security, CloudFront, IAM 06/11/2025 06/11/2025 - 5 - Chuẩn bị tài liệu thuyết trình cuối kỳ + Slide giới thiệu kiến trúc + Nội dung demo (nếu có) 07/11/2025 07/11/2025 - 6 - Tổng kết cuối tuần + Hoàn thiện Worklog, đẩy lên GitHub/Hugo site + Kiểm tra lại toàn bộ nội dung trước khi nộp 08/11/2025 08/11/2025 - Thành tựu Tuần 9 Hoàn thành bản kiến trúc hệ thống hoàn chỉnh, bao gồm:\nVPC với public/private subnets EC2 + ALB + Auto Scaling RDS + S3 + CloudFront IAM roles/policies + Security Groups CloudWatch + CloudTrail Viết và hoàn thiện báo cáo tổng kết AWS Cloud Journey, thể hiện đầy đủ:\nKiến thức đã học Dịch vụ đã triển khai Giải thích kiến trúc và lý do lựa chọn Củng cố kiến thức về Security, Networking, Compute, Storage, Serverless, Monitoring.\nChuẩn bị đầy đủ slide thuyết trình, hình ảnh, sơ đồ kiến trúc, và demo nhỏ.\nSẵn sàng cho buổi báo cáo Final Presentation của chương trình.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.10-week10/",
	"title": "Nhật ký Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 10 Hoàn thiện Proposal dự án theo yêu cầu chương trình. Nghiên cứu kiến thức kiến trúc đám mây để có thể vẽ sơ đồ AWS Architecture chuẩn theo best practices. Chuẩn bị nội dung cấu trúc, luồng dữ liệu và các dịch vụ AWS sẽ xuất hiện trong kiến trúc cuối cùng. Tổng quan Nhiệm vụ Tuần Ngày Hoạt động Ngày bắt đầu Ngày kết thúc Tài liệu tham khảo 1 - Bắt đầu viết Project Proposal + Viết phần Executive Summary + Xác định Problem Statement và mục tiêu dự án 10/11/2025 10/11/2025 - 2 - Hoàn thiện Proposal phần Solution Overview + Liệt kê dịch vụ AWS cần dùng + Định nghĩa luồng dữ liệu chính của hệ thống 11/11/2025 11/11/2025 https://aws.amazon.com/architecture/ 3 - Học kiến thức để vẽ AWS Architecture Diagram + Tìm hiểu kiến trúc chuẩn 3-tier, Serverless, Event-driven + Làm quen biểu tượng AWS Architecture Icons 12/11/2025 12/11/2025 https://aws.amazon.com/architecture/icons/ 4 - Thực hành phác thảo sơ đồ kiến trúc + Xây dựng VPC, Subnets + Thêm ALB, EC2, RDS, S3, IAM vào sơ đồ + Xác định các điểm kết nối và bảo mật 13/11/2025 13/11/2025 - 5 - Cập nhật Proposal dựa trên kiến trúc đã vẽ + Thêm Architecture Diagram + Viết Technical Implementation 14/11/2025 14/11/2025 - 6 - Tổng kết tuần 10 + Review Proposal hoàn chỉnh + Kiểm tra lại toàn bộ kiến trúc trước khi nộp 15/11/2025 15/11/2025 - Thành tựu Tuần 10 Hoàn thành bản Project Proposal với đầy đủ:\nExecutive Summary Problem Statement Proposed Architecture Expected Outcomes Technical Implementation Risk Assessment Nắm vững kiến thức để vẽ sơ đồ kiến trúc AWS:\nBiểu tượng AWS Architecture Icons Cách trình bày VPC, Subnets, Routing Thiết lập Compute, Storage, Database, Networking trong sơ đồ Vẽ được bản phác thảo sơ đồ kiến trúc ban đầu, bao gồm:\nVPC (Public \u0026amp; Private) ALB + EC2 Auto Scaling RDS Database S3 Storage Layer IAM + Security Groups + Flow Logs Chuẩn bị đầy đủ nội dung để bước sang giai đoạn trình bày cuối cùng trong các tuần tiếp theo.\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 11: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://dangkhoi88x.github.io/AWS-fcj/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]